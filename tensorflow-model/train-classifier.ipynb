{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Presets\n",
    "\n",
    "1. Run setup notebook!\n",
    "2. Add Slim modules to Python Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contextlib2 in /opt/conda/lib/python3.7/site-packages (0.6.0.post1)\n",
      "env: PYTHONPATH=:models/research/slim\n"
     ]
    }
   ],
   "source": [
    "!pip install contextlib2\n",
    "import os\n",
    "slim_path = \":models/research/slim\"\n",
    "old_path = (os.environ.get(\"PYTHONPATH\") or '')\n",
    "\n",
    "if not (slim_path in old_path):\n",
    "    new_python_path = old_path + slim_path\n",
    "\n",
    "%env PYTHONPATH=$new_python_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Download and build visual wakeword dataset\n",
    "\n",
    "The existing dataset (download via the setup notebook) is designed to be used for training models for localization, so the images aren't labeled with the \"contains a X\", \"doesn't contain a X\" categories that we want to train for. Instead each image comes with a list of bounding boxes for all of the objects it contains. \"X\" is one of these object categories, so to get to the classification labels we want, we have to look for images with bounding boxes for people. To make sure that they aren't too tiny to be recognizable we also need to exclude very small bounding boxes. Slim contains a script to convert the bounding box into labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL='person'\n",
    "%cd ~\n",
    "! python sparky-rooms/tensorflow-model/models/research/slim/download_and_convert_data.py \\\n",
    "--dataset_name=visualwakewords \\\n",
    "--dataset_dir=dataset/visualwakewords \\\n",
    "--small_object_area_threshold=0.005 \\\n",
    "--foreground_class_of_interest=$LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n",
      "python: can't open file 'sparky-rooms/tensorflow-model/models/research/slim/datasets/build_visualwakewords_data.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%cd ~\n",
    "! python sparky-rooms/tensorflow-model/models/research/slim/datasets/build_visualwakewords_data.py \\\n",
    "--logtostderr \\\n",
    "--train_image_dir=dataset/raw-data/train2014 \\\n",
    "--val_image_dir=dataset/raw-data/val2014 \\\n",
    "--train_annotations_file=dataset/raw-data/annotations/instances_train2014.json \\\n",
    "--val_annotations_file=dataset/raw-data/annotations/instances_val2014.json \\\n",
    "--output_dir=dataset/visual-wake-words \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python models/research/slim/train_image_classifier.py \\\n",
    "    --train_dir=vww_96_grayscale \\\n",
    "    --dataset_name=visualwakewords \\\n",
    "    --dataset_split_name=train \\\n",
    "    --dataset_dir=dataset/visual-wake-words \\\n",
    "    --model_name=mobilenet_v1_025 \\\n",
    "    --preprocessing_name=mobilenet_v1 \\\n",
    "    --train_image_size=96 \\\n",
    "    --input_grayscale=True \\\n",
    "    --save_summaries_secs=300 \\\n",
    "    --learning_rate=0.045 \\\n",
    "    --label_smoothing=0.1 \\\n",
    "    --learning_rate_decay_factor=0.98 \\\n",
    "    --num_epochs_per_decay=2.5 \\\n",
    "    --moving_average_decay=0.9999 \\\n",
    "    --batch_size=96 \\\n",
    "    --max_number_of_steps=1000000"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
